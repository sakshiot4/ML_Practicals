{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc3c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Gender  PlanType  MonthlyUsage Churn\n",
      "0   21  Female   Regular            15    No\n",
      "1   45  Female   Economy            41    No\n",
      "2   44  Female   Economy            40    No\n",
      "3   31  Female   Regular            23   Yes\n",
      "4   33  Female   Regular            12    No\n",
      "5   42  Female   Regular            52    No\n",
      "6   20  Female     Ultra            57   Yes\n",
      "7   26    Male     Ultra            23    No\n",
      "8   37  Female  Advanced            31    No\n",
      "9   26    Male   Economy            23    No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"telecom_data.csv\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ebd5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns ['Age', 'Gender', 'PlanType', 'MonthlyUsage', 'Churn']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Age           150 non-null    int64 \n",
      " 1   Gender        150 non-null    object\n",
      " 2   PlanType      150 non-null    object\n",
      " 3   MonthlyUsage  150 non-null    int64 \n",
      " 4   Churn         150 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 6.0+ KB\n",
      "\n",
      "Dataset info: \n",
      " None\n",
      "\n",
      "Dataset Completeness: \n",
      " Age             0\n",
      "Gender          0\n",
      "PlanType        0\n",
      "MonthlyUsage    0\n",
      "Churn           0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Dataset Consistency: \n",
      " Age              int64\n",
      "Gender          object\n",
      "PlanType        object\n",
      "MonthlyUsage     int64\n",
      "Churn           object\n",
      "dtype: object\n",
      "\n",
      "Describe dataset: \n",
      "               Age  MonthlyUsage\n",
      "count  150.000000    150.000000\n",
      "mean    35.193333     33.693333\n",
      "std     10.841566     15.923031\n",
      "min     19.000000      3.000000\n",
      "25%     25.000000     23.000000\n",
      "50%     35.000000     35.000000\n",
      "75%     44.000000     50.000000\n",
      "max     54.000000     59.000000\n"
     ]
    }
   ],
   "source": [
    "print('Columns',data.columns.to_list())\n",
    "\n",
    "print('\\nDataset info: \\n',data.info())\n",
    "\n",
    "print(\"\\nDataset Completeness: \\n\",data.isnull().sum())\n",
    "\n",
    "print(\"\\n\\nDataset Consistency: \\n\",data.dtypes)\n",
    "\n",
    "print(\"\\nDescribe dataset: \\n\", data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset Bias\n",
      "\n",
      "Gender\n",
      "Female    0.793333\n",
      "Male      0.206667\n",
      "Name: proportion, dtype: float64\n",
      "Churn\n",
      "No     0.893333\n",
      "Yes    0.106667\n",
      "Name: proportion, dtype: float64\n",
      "Age\n",
      "45    0.106667\n",
      "21    0.093333\n",
      "44    0.093333\n",
      "42    0.080000\n",
      "20    0.080000\n",
      "26    0.073333\n",
      "37    0.060000\n",
      "31    0.053333\n",
      "54    0.046667\n",
      "53    0.046667\n",
      "24    0.040000\n",
      "34    0.033333\n",
      "35    0.033333\n",
      "25    0.033333\n",
      "43    0.026667\n",
      "33    0.026667\n",
      "38    0.020000\n",
      "32    0.020000\n",
      "19    0.020000\n",
      "52    0.013333\n",
      "Name: proportion, dtype: float64\n",
      "PlanType\n",
      "Advanced    0.273333\n",
      "Ultra       0.220000\n",
      "Regular     0.213333\n",
      "Standard    0.160000\n",
      "Economy     0.133333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Dataset Bias\\n\")\n",
    "print(data['Gender'].value_counts(normalize=True))\n",
    "print(data['Churn'].value_counts(normalize=True))\n",
    "#print(data['Age'].value_counts(normalize=True))\n",
    "print(data['PlanType'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65ec58",
   "metadata": {},
   "source": [
    "| Field | Details |\n",
    "|------|--------|\n",
    "| **Dataset Name** | `telecom_churn_data.csv` |\n",
    "| **Description** | Contains customer demographic and usage details from a telecom company used to predict churn behavior. The dataset is used to demonstrate **data quality checks**, **feature encoding**, and **model evaluation** using **Logistic Regression**. |\n",
    "| **Features** | Age, Gender, PlanType, MonthlyUsage |\n",
    "| **Target Variable** | Churn (Yes = churned, No = retained) |\n",
    "| **Number of Rows** | 150 |\n",
    "| **Null Handling** | No missing values detected across any feature (`isnull().sum()` confirms all zeroes) |\n",
    "| **Feature Types** | - **Age**: Numeric (int)<br>- **Gender**: Categorical (object, Nominal)<br>- **PlanType**: Categorical (object, Nominal)<br>- **MonthlyUsage**: Numeric (int)<br>- **Churn**: Categorical (binary target) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c60635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat: \n",
      " ['Gender', 'PlanType']\n",
      "Num: \n",
      " ['Age', 'MonthlyUsage']\n"
     ]
    }
   ],
   "source": [
    "fdata = data.drop(columns=['Churn'])\n",
    "x = fdata\n",
    "y = data[\"Churn\"].map({'Yes':1, 'No':0})\n",
    "\n",
    "categorical = fdata.select_dtypes(include='object').columns\n",
    "numerical= fdata.select_dtypes(exclude='object').columns\n",
    "\n",
    "print(\"Cat: \\n\", list(categorical))\n",
    "print(\"Num: \\n\", list(numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56b9f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd Encoded Columnsa:  ['Age', 'MonthlyUsage', 'Gender_Male', 'PlanType_Economy', 'PlanType_Regular', 'PlanType_Standard', 'PlanType_Ultra']\n",
      "0      False\n",
      "1       True\n",
      "2       True\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "145    False\n",
      "146    False\n",
      "147    False\n",
      "148     True\n",
      "149    False\n",
      "Name: PlanType_Economy, Length: 150, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Feature encoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "x_encoded_gd = pd.get_dummies(\n",
    "    x, columns=categorical,\n",
    "    drop_first=True\n",
    ")\n",
    "print(\"gd Encoded Columnsa: \", x_encoded_gd.columns.tolist())\n",
    "#print(x_encoded_gd['Gender_Male'])\n",
    "print(x_encoded_gd['PlanType_Economy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0131fcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#one hot encoding\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first', sparse_output=False,\n",
    ")\n",
    "\n",
    "encoded_array = ohe.fit_transform(x[categorical])\n",
    "print(encoded_array)\n",
    "\n",
    "#covert back to DF.\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_array, columns = ohe.get_feature_names_out(categorical)\n",
    ")\n",
    "#print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9c66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Age  MonthlyUsage  Gender_Male  PlanType_Economy  PlanType_Regular  \\\n",
      "0   -1.313545     -1.177914        False             False              True   \n",
      "1    0.907574      0.460411        False              True             False   \n",
      "2    0.815027      0.397399        False              True             False   \n",
      "3   -0.388079     -0.673814        False             False              True   \n",
      "4   -0.202986     -1.366951        False             False              True   \n",
      "..        ...           ...          ...               ...               ...   \n",
      "145 -1.498638     -1.934064        False             False             False   \n",
      "146  0.629934      1.153549        False             False             False   \n",
      "147  1.740493     -1.682014        False             False             False   \n",
      "148 -1.406091      1.468612        False              True             False   \n",
      "149 -0.388079     -0.673814        False             False             False   \n",
      "\n",
      "     PlanType_Standard  PlanType_Ultra  \n",
      "0                False           False  \n",
      "1                False           False  \n",
      "2                False           False  \n",
      "3                False           False  \n",
      "4                False           False  \n",
      "..                 ...             ...  \n",
      "145              False           False  \n",
      "146              False           False  \n",
      "147              False            True  \n",
      "148              False           False  \n",
      "149               True           False  \n",
      "\n",
      "[150 rows x 7 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Age', 'MonthlyUsage'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(x_scaled_gd)\n\u001b[32m      6\u001b[39m x_scaled_ohe = encoded_df.copy()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m x_scaled_ohe[numerical] = scalar.fit_transform(\u001b[43mx_scaled_ohe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(x_scaled_ohe)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ITCS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ITCS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ITCS\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['Age', 'MonthlyUsage'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "scalar = StandardScaler()\n",
    "x_scaled_gd = x_encoded_gd.copy()\n",
    "x_scaled_gd[numerical]= scalar.fit_transform(x_scaled_gd[numerical])\n",
    "print(x_scaled_gd)\n",
    "\n",
    "x_scaled_ohe = encoded_df.copy()\n",
    "x_scaled_ohe[numerical] = scalar.fit_transform(encoded_df[numerical])\n",
    "print(x_scaled_ohe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
